{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d6087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 63 samples in dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import jsonlines\n",
    "\n",
    "WINDOW_SIZE = 5 \n",
    "\n",
    "def parse_html(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    messages = []\n",
    "    for msg in soup.find_all(\"div\", class_=\"body\"):\n",
    "       \n",
    "        if msg.find(\"div\", class_=\"from_name\"):\n",
    "            name_tag = msg.find(\"div\", class_=\"from_name\")\n",
    "\n",
    "        text_tag = msg.find(\"div\", class_=\"text\")\n",
    "        if not text_tag:\n",
    "            continue\n",
    "\n",
    "        sender = name_tag.get_text(strip=True)\n",
    "        text = text_tag.get_text(\" \", strip=True)\n",
    "        if not text: \n",
    "            continue\n",
    "\n",
    "        role = \"Me\" if sender == \"YesImBatMan\" else \"user\"\n",
    "        messages.append({\"role\": role, \"content\": text})\n",
    "    return messages\n",
    "\n",
    "def build_dataset(messages, window_size=WINDOW_SIZE):\n",
    "    dataset = []\n",
    "    for i in range(len(messages)):\n",
    "        if messages[i][\"role\"] == \"Me\":\n",
    "            context = messages[max(0, i-window_size):i]\n",
    "            if not any(m[\"role\"]==\"user\" for m in context):\n",
    "                continue\n",
    "            dataset.append({\n",
    "                \"messages\": context + [messages[i]]\n",
    "            })\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    msgs = parse_html(\"messages.html\")\n",
    "    dataset = build_dataset(msgs, WINDOW_SIZE)\n",
    "\n",
    "    with jsonlines.open(\"dataset.jsonl\", \"w\") as writer:\n",
    "        for d in dataset:\n",
    "            writer.write(d)\n",
    "\n",
    "    print(\"Saved\", len(dataset), \"samples in dataset.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b764e7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 63 samples in dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import jsonlines\n",
    "import re\n",
    "\n",
    "WINDOW_SIZE = 5\n",
    "ASSISTANT_NAME = \"YesImBatMan\"  # اسم تو در تلگرام\n",
    "\n",
    "def parse_html(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    messages = []\n",
    "    last_sender = None\n",
    "\n",
    "    for m in soup.find_all(\"div\", class_=\"message\"):\n",
    "        if \"service\" in m.get(\"class\", []):\n",
    "            continue\n",
    "\n",
    "        body = m.find(\"div\", class_=\"body\")\n",
    "        if not body:\n",
    "            continue\n",
    "\n",
    "        mid_raw = m.get(\"id\", \"\")\n",
    "        mid = int(re.sub(r\"\\D\", \"\", mid_raw)) if mid_raw else None\n",
    "\n",
    "        r = body.find(\"div\", class_=\"reply_to\")\n",
    "        reply_to = None\n",
    "        if r and r.find(\"a\") and r.find(\"a\").get(\"href\"):\n",
    "            href = r.find(\"a\").get(\"href\")\n",
    "            ref = re.sub(r\"\\D\", \"\", href or \"\")\n",
    "            reply_to = int(ref) if ref else None\n",
    "\n",
    "        name_tag = body.find(\"div\", class_=\"from_name\")\n",
    "        if name_tag:\n",
    "            last_sender = name_tag.get_text(strip=True)\n",
    "        sender = last_sender or \"\"\n",
    "\n",
    "        text_tag = body.find(\"div\", class_=\"text\")\n",
    "        if not text_tag:\n",
    "            continue\n",
    "        text = text_tag.get_text(\" \", strip=True)\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        role = \"assistant\" if sender == ASSISTANT_NAME else \"user\"\n",
    "        messages.append({\n",
    "            \"id\": mid,\n",
    "            \"role\": role,\n",
    "            \"sender\": sender,\n",
    "            \"content\": text,\n",
    "            \"reply_to\": reply_to\n",
    "        })\n",
    "\n",
    "    return messages\n",
    "\n",
    "def to_simple(m):\n",
    "    return {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
    "\n",
    "def trim_leading_assistants(context):\n",
    "    k = 0\n",
    "    while k < len(context) and context[k][\"role\"] == \"assistant\":\n",
    "        k += 1\n",
    "    return context[k:]\n",
    "\n",
    "def build_dataset(messages, window_size=WINDOW_SIZE, inject_style=\"raw\", add_marker=True):\n",
    "    \"\"\"\n",
    "    inject_style:\n",
    "      - 'raw'   : اگر پیام مرجع خارج پنجره باشد، خودش را به ابتدای کانتکست تزریق می‌کند\n",
    "      - 'quote' : اگر پیام مرجع خارج پنجره باشد، نسخه‌ی نقل‌قول‌شده‌اش را تزریق می‌کند\n",
    "      - None    : هیچ تزریقی انجام نمی‌دهد\n",
    "    add_marker:\n",
    "      - True  : همیشه قبل از پاسخ یک مارکر ⟪REPLY_TO ...⟫ قرار می‌دهد (چه مرجع داخل پنجره باشد چه بیرون)\n",
    "      - False : مارکر اضافه نمی‌شود\n",
    "    \"\"\"\n",
    "    idx_by_id = {m[\"id\"]: i for i, m in enumerate(messages) if m[\"id\"] is not None}\n",
    "    dataset = []\n",
    "\n",
    "    for idx, msg in enumerate(messages):\n",
    "        if msg[\"role\"] != \"assistant\":\n",
    "            continue\n",
    "\n",
    "        start = max(0, idx - window_size)\n",
    "        ctx_src = messages[start:idx]\n",
    "        context = [to_simple(x) for x in ctx_src]\n",
    "\n",
    "        # اگر پاسخ به پیام خاصی است:\n",
    "        ref_id = msg.get(\"reply_to\")\n",
    "        replied = None\n",
    "        if ref_id and ref_id in idx_by_id:\n",
    "            j = idx_by_id[ref_id]\n",
    "            replied = messages[j]\n",
    "\n",
    "            # اگر مرجع خارج از پنجره است، طبق inject_style تزریقش کن\n",
    "            if not (start <= j < idx):\n",
    "                if inject_style == \"raw\":\n",
    "                    context = [to_simple(replied)] + context\n",
    "                elif inject_style == \"quote\":\n",
    "                    q_sender = \"من\" if replied[\"role\"] == \"assistant\" else (replied.get(\"sender\") or \"user\")\n",
    "                    q_text = f\"> {q_sender}: {replied['content']}\"\n",
    "                    context = [{\"role\": \"user\", \"content\": q_text}] + context\n",
    "\n",
    "        # مارکر REPLY_TO را همیشه قبل از پاسخ بگذار (اگر add_marker=True و replied موجود است)\n",
    "        if add_marker and replied is not None:\n",
    "            sender_label = \"assistant\" if replied[\"role\"] == \"assistant\" else (\"user\")\n",
    "            marker = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"⟪REPLY_TO {sender_label}⟫ {replied['content']} ⟪/REPLY_TO⟫\"\n",
    "            }\n",
    "            context = context + [marker]\n",
    "\n",
    "        # تمیزکاری: با user شروع شود و قبل از پاسخ حداقل یک user باشد\n",
    "        context = trim_leading_assistants(context)\n",
    "        if not context or not any(m[\"role\"] == \"user\" for m in context):\n",
    "            continue\n",
    "\n",
    "        sample = {\"messages\": context + [to_simple(msg)]}\n",
    "        dataset.append(sample)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    msgs = parse_html(\"messages.html\")\n",
    "    dataset = build_dataset(msgs, WINDOW_SIZE, inject_style=\"raw\", add_marker=True)\n",
    "\n",
    "    with jsonlines.open(\"dataset.jsonl\", \"w\") as w:\n",
    "        for d in dataset:\n",
    "            w.write(d)\n",
    "\n",
    "    print(\"Saved\", len(dataset), \"samples in dataset.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "846c165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked links → dataset_links_masked.jsonl\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import jsonlines\n",
    "\n",
    "IN_PATH  = \"dataset.jsonl\"\n",
    "OUT_PATH = \"dataset_links_masked.jsonl\"\n",
    "\n",
    "# URLهای با پروتکل (http/https/ftp و هر scheme مثل vmess://, vless://, trojan://, ss:// و ...)\n",
    "PROTO_URL_RE = re.compile(\n",
    "    r\"(?i)\\b(?:[a-z][a-z0-9+.\\-]*://)[^\\s<>()]+\"\n",
    ")\n",
    "\n",
    "# آدرس‌های بدون پروتکل که با www شروع می‌شوند\n",
    "WWW_URL_RE = re.compile(\n",
    "    r\"(?i)\\bwww\\.[^\\s<>()]+\\.[a-z]{2,}(?:/[^\\s<>()]*)?\"\n",
    ")\n",
    "\n",
    "def mask_links(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    t = PROTO_URL_RE.sub(\"[LINK]\", text)\n",
    "    t = WWW_URL_RE.sub(\"[LINK]\", t)\n",
    "    # کمی تمیزکاری فاصله‌ها\n",
    "    t = re.sub(r\"\\s{2,}\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "with jsonlines.open(OUT_PATH, \"w\") as w, open(IN_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        msgs = obj.get(\"messages\", [])\n",
    "        for m in msgs:\n",
    "            if \"content\" in m:\n",
    "                m[\"content\"] = mask_links(m[\"content\"])\n",
    "        w.write({\"messages\": msgs})\n",
    "\n",
    "print(\"Masked links →\", OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345f7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 66 samples -> dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "# build_dataset_clean.py\n",
    "from bs4 import BeautifulSoup\n",
    "import jsonlines\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# ------------------------ تنظیمات ------------------------\n",
    "WINDOW_SIZE = 5                 # چند پیام قبل از پاسخ را بیاور\n",
    "ASSISTANT_NAME = \"YesImBatMan\"  # اسم اکانت خودت در تلگرام\n",
    "INPUT_HTML = \"messages.html\"    # خروجی HTML تلگرام\n",
    "OUTPUT_JSONL = \"dataset.jsonl\"  # خروجی دیتاست\n",
    "\n",
    "# اگر خواستی لینک‌های تلگرام/URL را جایگزین کنی:\n",
    "LINK_PLACEHOLDER = \"«لینک»\"     # None بگذار تا اصلاً جایگزینی نشود\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    # حذف بلوک‌های REPLY_TO قدیمی اگر در متن آمده باشد\n",
    "    s = re.sub(r\"⟪REPLY_TO.*?⟫\", \"\", s, flags=re.DOTALL)\n",
    "\n",
    "    # جایگزینی [LINK] یا URLها (دلخواه)\n",
    "    if LINK_PLACEHOLDER is not None:\n",
    "        s = s.replace(\"[LINK]\", LINK_PLACEHOLDER)\n",
    "        # URL ساده:\n",
    "        s = re.sub(r\"https?://\\S+\", LINK_PLACEHOLDER, s)\n",
    "\n",
    "    # فاصله‌ها و \\n های اضافی\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def parse_html(path: str) -> List[Dict]:\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    messages = []\n",
    "    last_sender = None\n",
    "\n",
    "    for m in soup.find_all(\"div\", class_=\"message\"):\n",
    "        if \"service\" in m.get(\"class\", []):\n",
    "            continue\n",
    "\n",
    "        body = m.find(\"div\", class_=\"body\")\n",
    "        if not body:\n",
    "            continue\n",
    "\n",
    "        # id پیام\n",
    "        mid_raw = m.get(\"id\", \"\")\n",
    "        mid = int(re.sub(r\"\\D\", \"\", mid_raw)) if mid_raw else None\n",
    "\n",
    "        # reply_to\n",
    "        r = body.find(\"div\", class_=\"reply_to\")\n",
    "        reply_to = None\n",
    "        if r and r.find(\"a\") and r.find(\"a\").get(\"href\"):\n",
    "            href = r.find(\"a\").get(\"href\")\n",
    "            ref = re.sub(r\"\\D\", \"\", href or \"\")\n",
    "            reply_to = int(ref) if ref else None\n",
    "\n",
    "        # sender\n",
    "        name_tag = body.find(\"div\", class_=\"from_name\")\n",
    "        if name_tag:\n",
    "            last_sender = name_tag.get_text(strip=True)\n",
    "        sender = last_sender or \"\"\n",
    "\n",
    "        # متن\n",
    "        text_tag = body.find(\"div\", class_=\"text\")\n",
    "        if not text_tag:\n",
    "            continue\n",
    "        raw = text_tag.get_text(\"\\n\", strip=True)  # \\n برای پاراگراف‌های چندبخشی\n",
    "        content = clean_text(raw)\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        role = \"assistant\" if sender == ASSISTANT_NAME else \"user\"\n",
    "        messages.append({\n",
    "            \"id\": mid,\n",
    "            \"role\": role,\n",
    "            \"sender\": sender,\n",
    "            \"content\": content,\n",
    "            \"reply_to\": reply_to\n",
    "        })\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "def to_simple(m: Dict) -> Dict:\n",
    "    return {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
    "\n",
    "\n",
    "def merge_same_role(seq: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"ادغام پیام‌های پشت‌سرهم با نقش یکسان (content ها با \\n چسبانده می‌شوند).\"\"\"\n",
    "    out = []\n",
    "    for m in seq:\n",
    "        if not out:\n",
    "            out.append(dict(m))\n",
    "        elif out[-1][\"role\"] == m[\"role\"]:\n",
    "            out[-1][\"content\"] += \"\\n\" + m[\"content\"]\n",
    "        else:\n",
    "            out.append(dict(m))\n",
    "    return out\n",
    "\n",
    "\n",
    "def enforce_alternation(seq: List[Dict]) -> Optional[List[Dict]]:\n",
    "    \"\"\"یکی‌درمیون کردن نقش‌ها؛ با user شروع و با assistant پایان.\n",
    "       اگر ممکن نبود، None برمی‌گرداند.\"\"\"\n",
    "    if not seq:\n",
    "        return None\n",
    "\n",
    "    # اگر با assistant شروع شده → یک user مینیمال جلویش بگذاریم\n",
    "    if seq[0][\"role\"] == \"assistant\":\n",
    "        seq = [{\"role\": \"user\", \"content\": \"…\"}] + seq\n",
    "\n",
    "    # اگر با system شروع شده، ساده‌ترین: به user تبدیل کنیم (یا می‌شود حذف کرد)\n",
    "    if seq[0][\"role\"] == \"system\":\n",
    "        seq[0] = {\"role\": \"user\", \"content\": seq[0].get(\"content\", \"\") or \"…\"}\n",
    "\n",
    "    # ادغام مجدد\n",
    "    seq = merge_same_role(seq)\n",
    "\n",
    "    # اگر آخرین پیام user بود، حذفش کن (بدون پاسخ مانده)\n",
    "    if seq and seq[-1][\"role\"] == \"user\":\n",
    "        seq = seq[:-1]\n",
    "\n",
    "    # حالا باید یکی‌درمیون باشد\n",
    "    if not seq or len(seq) < 2:\n",
    "        return None\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i][\"role\"] == seq[i-1][\"role\"]:\n",
    "            # اگر تکراری شد، ادغام و دوباره چک\n",
    "            seq = merge_same_role(seq)\n",
    "            # دوباره بررسی:\n",
    "            ok = True\n",
    "            for j in range(1, len(seq)):\n",
    "                if seq[j][\"role\"] == seq[j-1][\"role\"]:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if not ok:\n",
    "                return None\n",
    "            break\n",
    "\n",
    "    # باید با user شروع و با assistant پایان یابد\n",
    "    if seq[0][\"role\"] != \"user\" or seq[-1][\"role\"] != \"assistant\":\n",
    "        return None\n",
    "\n",
    "    # حذف پیام‌های خالی\n",
    "    seq = [m for m in seq if m[\"content\"].strip()]\n",
    "    return seq if len(seq) >= 2 else None\n",
    "\n",
    "\n",
    "def build_dataset(messages: List[Dict], window_size: int = WINDOW_SIZE) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    برای هر پیام assistant یک نمونه می‌سازیم:\n",
    "      context (حداکثر window_size پیام قبل) + همان پاسخ assistant\n",
    "    اگر reply_to به پیامی خارج از پنجره اشاره داشت، یک «نقل‌قول کوتاه»\n",
    "    به‌عنوان اولین پیام user داخل context اضافه می‌کنیم (بدون مارکر خاص).\n",
    "    \"\"\"\n",
    "    # ایندکس سریع برای دسترسی به پیام‌ها با id\n",
    "    idx_by_id = {m[\"id\"]: i for i, m in enumerate(messages) if m[\"id\"] is not None}\n",
    "    out = []\n",
    "\n",
    "    for idx, msg in enumerate(messages):\n",
    "        if msg[\"role\"] != \"assistant\":\n",
    "            continue\n",
    "\n",
    "        # کانتکست خام\n",
    "        start = max(0, idx - window_size)\n",
    "        context = [to_simple(x) for x in messages[start:idx]]\n",
    "\n",
    "        # اگر reply_to دارد و بیرون از پنجره است، یک نقل‌قول کوتاه اضافه کن\n",
    "        ref_id = msg.get(\"reply_to\")\n",
    "        if ref_id and ref_id in idx_by_id:\n",
    "            j = idx_by_id[ref_id]\n",
    "            if not (start <= j < idx):\n",
    "                ref = messages[j]\n",
    "                quote = f\"> {('من' if ref['role']=='assistant' else ref.get('sender') or 'user')}: {ref['content']}\"\n",
    "                context = [{\"role\": \"user\", \"content\": quote}] + context\n",
    "\n",
    "        # تمیزکاری: ادغام نقش‌های پشت‌سرهم و enforce alternation\n",
    "        context = merge_same_role(context)\n",
    "        sample_seq = context + [to_simple(msg)]\n",
    "        sample_seq = enforce_alternation(sample_seq)\n",
    "        if sample_seq is None:\n",
    "            continue\n",
    "\n",
    "        out.append({\"messages\": sample_seq})\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    msgs = parse_html(INPUT_HTML)\n",
    "    dataset = build_dataset(msgs, WINDOW_SIZE)\n",
    "\n",
    "    with jsonlines.open(OUTPUT_JSONL, \"w\") as w:\n",
    "        for d in dataset:\n",
    "            w.write(d)\n",
    "\n",
    "    print(f\"Saved {len(dataset)} samples -> {OUTPUT_JSONL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b872ecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages (2).html: 626 samples\n",
      "messages.html: 66 samples\n",
      "messages2.html: 568 samples\n",
      "messages2.html: 568 samples\n",
      "messages3.html: 578 samples\n",
      "messages3.html: 578 samples\n",
      "messages4.html: 564 samples\n",
      "messages4.html: 564 samples\n",
      "messages5.html: 374 samples\n",
      "Saved 2776 samples -> dataset.jsonl\n",
      "messages5.html: 374 samples\n",
      "Saved 2776 samples -> dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import jsonlines, re, glob\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# -------- تنظیمات --------\n",
    "WINDOW_SIZE = 5\n",
    "ASSISTANT_NAME = \"YesImBatMan\"\n",
    "INPUT_HTML = \"messages.html\"\n",
    "OUTPUT_JSONL = \"dataset.jsonl\"\n",
    "LINK_PLACEHOLDER = \"«لینک»\"   # اگر نمی‌خوای لینک‌ها عوض بشن = None\n",
    "# -------------------------\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s: return \"\"\n",
    "    s = re.sub(r\"⟪REPLY_TO.*?⟫\", \"\", s, flags=re.DOTALL)\n",
    "    if LINK_PLACEHOLDER is not None:\n",
    "        s = s.replace(\"[LINK]\", LINK_PLACEHOLDER)\n",
    "        s = re.sub(r\"https?://\\S+\", LINK_PLACEHOLDER, s)\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def parse_html(path: str) -> List[Dict]:\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    messages, last_sender = [], None\n",
    "    for m in soup.find_all(\"div\", class_=\"message\"):\n",
    "        if \"service\" in m.get(\"class\", []): \n",
    "            continue\n",
    "        body = m.find(\"div\", class_=\"body\")\n",
    "        if not body: \n",
    "            continue\n",
    "\n",
    "        mid_raw = m.get(\"id\", \"\")\n",
    "        mid = int(re.sub(r\"\\D\", \"\", mid_raw)) if mid_raw else None\n",
    "\n",
    "        r = body.find(\"div\", class_=\"reply_to\")\n",
    "        reply_to = None\n",
    "        if r and r.find(\"a\") and r.find(\"a\").get(\"href\"):\n",
    "            href = r.find(\"a\").get(\"href\") or \"\"\n",
    "            ref = re.sub(r\"\\D\", \"\", href)\n",
    "            reply_to = int(ref) if ref else None\n",
    "\n",
    "        name_tag = body.find(\"div\", class_=\"from_name\")\n",
    "        if name_tag: \n",
    "            last_sender = name_tag.get_text(strip=True)\n",
    "        sender = last_sender or \"\"\n",
    "\n",
    "        text_tag = body.find(\"div\", class_=\"text\")\n",
    "        if not text_tag: \n",
    "            continue\n",
    "        content = clean_text(text_tag.get_text(\"\\n\", strip=True))\n",
    "        if not content: \n",
    "            continue\n",
    "\n",
    "        role = \"assistant\" if sender == ASSISTANT_NAME else \"user\"\n",
    "        messages.append({\"id\": mid, \"role\": role, \"sender\": sender, \"content\": content, \"reply_to\": reply_to})\n",
    "    return messages\n",
    "\n",
    "def to_simple(m: Dict) -> Dict:\n",
    "    return {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
    "\n",
    "def merge_same_role(seq: List[Dict]) -> List[Dict]:\n",
    "    out = []\n",
    "    for m in seq:\n",
    "        if not out or out[-1][\"role\"] != m[\"role\"]:\n",
    "            out.append({\"role\": m[\"role\"], \"content\": m[\"content\"]})\n",
    "        else:\n",
    "            out[-1][\"content\"] += \"\\n\" + m[\"content\"]\n",
    "    return out\n",
    "\n",
    "def enforce_user_first_and_alternate(seq: List[Dict]) -> Optional[List[Dict]]:\n",
    "    if not seq: \n",
    "        return None\n",
    "    # نباید با assistant شروع شود و هیچ پیام ساختگی هم اضافه نمی‌کنیم\n",
    "    if seq[0][\"role\"] != \"user\": \n",
    "        return None\n",
    "    seq = merge_same_role(seq)\n",
    "    # اگر با user تمام شد، آن نمونه را کنار بگذاریم (بدون پاسخ)\n",
    "    if seq[-1][\"role\"] != \"assistant\":\n",
    "        return None\n",
    "    # یکی‌درمیان بودن نقش‌ها\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i][\"role\"] == seq[i-1][\"role\"]:\n",
    "            return None\n",
    "    # محتوای خالی حذف\n",
    "    seq = [m for m in seq if m[\"content\"].strip()]\n",
    "    return seq if len(seq) >= 2 else None\n",
    "\n",
    "def build_dataset(messages: List[Dict], window_size: int = WINDOW_SIZE) -> List[Dict]:\n",
    "    idx_by_id = {m[\"id\"]: i for i, m in enumerate(messages) if m[\"id\"] is not None}\n",
    "    out = []\n",
    "\n",
    "    for idx, msg in enumerate(messages):\n",
    "        if msg[\"role\"] != \"assistant\":\n",
    "            continue\n",
    "\n",
    "        # کانتکست پایه\n",
    "        start = max(0, idx - window_size)\n",
    "\n",
    "        # اگر کانتکست با assistant شروع می‌شود، کمی عقب‌گرد تا به user برسیم\n",
    "        back = start\n",
    "        while back > 0 and messages[back][\"role\"] == \"assistant\":\n",
    "            back -= 1\n",
    "        start = back\n",
    "\n",
    "        context = [to_simple(x) for x in messages[start:idx]]\n",
    "\n",
    "        # اگر reply_to بیرون پنجره است و «متن مرجع» وجود دارد، یک نقل‌قول کوتاهِ user اولِ کانتکست درج کن\n",
    "        ref_id = msg.get(\"reply_to\")\n",
    "        if ref_id and ref_id in idx_by_id:\n",
    "            j = idx_by_id[ref_id]\n",
    "            if not (start <= j < idx):\n",
    "                ref = messages[j]\n",
    "                quote_user = \"من\" if ref[\"role\"] == \"assistant\" else (ref.get(\"sender\") or \"user\")\n",
    "                quote = f\"> {quote_user}: {ref['content']}\"\n",
    "                context = [{\"role\": \"user\", \"content\": quote}] + context\n",
    "\n",
    "        # ادغام و قوانین\n",
    "        context = merge_same_role(context)\n",
    "        seq = context + [to_simple(msg)]\n",
    "        seq = enforce_user_first_and_alternate(seq)\n",
    "        if seq is None:\n",
    "            continue\n",
    "\n",
    "        out.append({\"messages\": seq})\n",
    "\n",
    "    return out\n",
    "\n",
    "# اجرا برای تمام فایل‌های HTML در این پوشه\n",
    "html_files = sorted(glob.glob(\"*.html\"))\n",
    "\n",
    "total = 0\n",
    "with jsonlines.open(OUTPUT_JSONL, \"w\") as w:\n",
    "    for fp in html_files:\n",
    "        msgs = parse_html(fp)\n",
    "        dataset = build_dataset(msgs, WINDOW_SIZE)\n",
    "        for d in dataset:\n",
    "            w.write(d)\n",
    "        print(f\"{fp}: {len(dataset)} samples\")\n",
    "        total += len(dataset)\n",
    "\n",
    "print(f\"Saved {total} samples -> {OUTPUT_JSONL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a604851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages.html: 551 samples\n",
      "messages10.html: 6 samples\n",
      "messages10.html: 6 samples\n",
      "messages100.html: 15 samples\n",
      "messages100.html: 15 samples\n",
      "messages101.html: 445 samples\n",
      "messages101.html: 445 samples\n",
      "messages102.html: 471 samples\n",
      "messages102.html: 471 samples\n",
      "messages103.html: 10 samples\n",
      "messages103.html: 10 samples\n",
      "messages104.html: 437 samples\n",
      "messages104.html: 437 samples\n",
      "messages105.html: 526 samples\n",
      "messages105.html: 526 samples\n",
      "messages106.html: 11 samples\n",
      "messages106.html: 11 samples\n",
      "messages107.html: 519 samples\n",
      "messages107.html: 519 samples\n",
      "messages108.html: 13 samples\n",
      "messages108.html: 13 samples\n",
      "messages109.html: 441 samples\n",
      "messages109.html: 441 samples\n",
      "messages11.html: 10 samples\n",
      "messages11.html: 10 samples\n",
      "messages110.html: 460 samples\n",
      "messages110.html: 460 samples\n",
      "messages111.html: 568 samples\n",
      "messages111.html: 568 samples\n",
      "messages112.html: 526 samples\n",
      "messages112.html: 526 samples\n",
      "messages113.html: 498 samples\n",
      "messages113.html: 498 samples\n",
      "messages114.html: 517 samples\n",
      "messages114.html: 517 samples\n",
      "messages115.html: 524 samples\n",
      "messages115.html: 524 samples\n",
      "messages116.html: 13 samples\n",
      "messages116.html: 13 samples\n",
      "messages117.html: 15 samples\n",
      "messages117.html: 15 samples\n",
      "messages118.html: 505 samples\n",
      "messages118.html: 505 samples\n",
      "messages119.html: 9 samples\n",
      "messages119.html: 9 samples\n",
      "messages12.html: 15 samples\n",
      "messages12.html: 15 samples\n",
      "messages120.html: 470 samples\n",
      "messages120.html: 470 samples\n",
      "messages121.html: 17 samples\n",
      "messages121.html: 17 samples\n",
      "messages122.html: 14 samples\n",
      "messages122.html: 14 samples\n",
      "messages123.html: 9 samples\n",
      "messages123.html: 9 samples\n",
      "messages124.html: 555 samples\n",
      "messages124.html: 555 samples\n",
      "messages125.html: 517 samples\n",
      "messages125.html: 517 samples\n",
      "messages126.html: 502 samples\n",
      "messages126.html: 502 samples\n",
      "messages127.html: 575 samples\n",
      "messages127.html: 575 samples\n",
      "messages128.html: 581 samples\n",
      "messages128.html: 581 samples\n",
      "messages129.html: 539 samples\n",
      "messages129.html: 539 samples\n",
      "messages13.html: 11 samples\n",
      "messages13.html: 11 samples\n",
      "messages130.html: 15 samples\n",
      "messages130.html: 15 samples\n",
      "messages131.html: 494 samples\n",
      "messages131.html: 494 samples\n",
      "messages132.html: 455 samples\n",
      "messages132.html: 455 samples\n",
      "messages133.html: 12 samples\n",
      "messages133.html: 12 samples\n",
      "messages134.html: 521 samples\n",
      "messages134.html: 521 samples\n",
      "messages135.html: 500 samples\n",
      "messages135.html: 500 samples\n",
      "messages136.html: 13 samples\n",
      "messages136.html: 13 samples\n",
      "messages137.html: 19 samples\n",
      "messages137.html: 19 samples\n",
      "messages138.html: 11 samples\n",
      "messages138.html: 11 samples\n",
      "messages139.html: 490 samples\n",
      "messages139.html: 490 samples\n",
      "messages14.html: 15 samples\n",
      "messages14.html: 15 samples\n",
      "messages140.html: 548 samples\n",
      "messages140.html: 548 samples\n",
      "messages141.html: 6 samples\n",
      "messages141.html: 6 samples\n",
      "messages142.html: 17 samples\n",
      "messages142.html: 17 samples\n",
      "messages143.html: 532 samples\n",
      "messages143.html: 532 samples\n",
      "messages144.html: 14 samples\n",
      "messages144.html: 14 samples\n",
      "messages145.html: 533 samples\n",
      "messages145.html: 533 samples\n",
      "messages146.html: 15 samples\n",
      "messages146.html: 15 samples\n",
      "messages147.html: 516 samples\n",
      "messages147.html: 516 samples\n",
      "messages148.html: 499 samples\n",
      "messages148.html: 499 samples\n",
      "messages149.html: 12 samples\n",
      "messages149.html: 12 samples\n",
      "messages15.html: 554 samples\n",
      "messages15.html: 554 samples\n",
      "messages150.html: 14 samples\n",
      "messages150.html: 14 samples\n",
      "messages151.html: 21 samples\n",
      "messages151.html: 21 samples\n",
      "messages152.html: 294 samples\n",
      "messages152.html: 294 samples\n",
      "messages16.html: 546 samples\n",
      "messages16.html: 546 samples\n",
      "messages17.html: 591 samples\n",
      "messages17.html: 591 samples\n",
      "messages18.html: 15 samples\n",
      "messages18.html: 15 samples\n",
      "messages19.html: 13 samples\n",
      "messages19.html: 13 samples\n",
      "messages2.html: 8 samples\n",
      "messages2.html: 8 samples\n",
      "messages20.html: 447 samples\n",
      "messages20.html: 447 samples\n",
      "messages21.html: 11 samples\n",
      "messages21.html: 11 samples\n",
      "messages22.html: 12 samples\n",
      "messages22.html: 12 samples\n",
      "messages23.html: 543 samples\n",
      "messages23.html: 543 samples\n",
      "messages24.html: 493 samples\n",
      "messages24.html: 493 samples\n",
      "messages25.html: 16 samples\n",
      "messages25.html: 16 samples\n",
      "messages26.html: 12 samples\n",
      "messages26.html: 12 samples\n",
      "messages27.html: 13 samples\n",
      "messages27.html: 13 samples\n",
      "messages28.html: 12 samples\n",
      "messages28.html: 12 samples\n",
      "messages29.html: 554 samples\n",
      "messages29.html: 554 samples\n",
      "messages3.html: 10 samples\n",
      "messages3.html: 10 samples\n",
      "messages30.html: 533 samples\n",
      "messages30.html: 533 samples\n",
      "messages31.html: 16 samples\n",
      "messages31.html: 16 samples\n",
      "messages32.html: 15 samples\n",
      "messages32.html: 15 samples\n",
      "messages33.html: 535 samples\n",
      "messages33.html: 535 samples\n",
      "messages34.html: 11 samples\n",
      "messages34.html: 11 samples\n",
      "messages35.html: 14 samples\n",
      "messages35.html: 14 samples\n",
      "messages36.html: 11 samples\n",
      "messages36.html: 11 samples\n",
      "messages37.html: 558 samples\n",
      "messages37.html: 558 samples\n",
      "messages38.html: 10 samples\n",
      "messages38.html: 10 samples\n",
      "messages39.html: 10 samples\n",
      "messages39.html: 10 samples\n",
      "messages4.html: 516 samples\n",
      "messages4.html: 516 samples\n",
      "messages40.html: 15 samples\n",
      "messages40.html: 15 samples\n",
      "messages41.html: 13 samples\n",
      "messages41.html: 13 samples\n",
      "messages42.html: 15 samples\n",
      "messages42.html: 15 samples\n",
      "messages43.html: 559 samples\n",
      "messages43.html: 559 samples\n",
      "messages44.html: 7 samples\n",
      "messages44.html: 7 samples\n",
      "messages45.html: 14 samples\n",
      "messages45.html: 14 samples\n",
      "messages46.html: 520 samples\n",
      "messages46.html: 520 samples\n",
      "messages47.html: 7 samples\n",
      "messages47.html: 7 samples\n",
      "messages48.html: 419 samples\n",
      "messages48.html: 419 samples\n",
      "messages49.html: 6 samples\n",
      "messages49.html: 6 samples\n",
      "messages5.html: 9 samples\n",
      "messages5.html: 9 samples\n",
      "messages50.html: 516 samples\n",
      "messages50.html: 516 samples\n",
      "messages51.html: 12 samples\n",
      "messages51.html: 12 samples\n",
      "messages52.html: 9 samples\n",
      "messages52.html: 9 samples\n",
      "messages53.html: 426 samples\n",
      "messages53.html: 426 samples\n",
      "messages54.html: 11 samples\n",
      "messages54.html: 11 samples\n",
      "messages55.html: 10 samples\n",
      "messages55.html: 10 samples\n",
      "messages56.html: 456 samples\n",
      "messages56.html: 456 samples\n",
      "messages57.html: 455 samples\n",
      "messages57.html: 455 samples\n",
      "messages58.html: 7 samples\n",
      "messages58.html: 7 samples\n",
      "messages59.html: 9 samples\n",
      "messages59.html: 9 samples\n",
      "messages6.html: 13 samples\n",
      "messages6.html: 13 samples\n",
      "messages60.html: 473 samples\n",
      "messages60.html: 473 samples\n",
      "messages61.html: 10 samples\n",
      "messages61.html: 10 samples\n",
      "messages62.html: 10 samples\n",
      "messages62.html: 10 samples\n",
      "messages63.html: 432 samples\n",
      "messages63.html: 432 samples\n",
      "messages64.html: 438 samples\n",
      "messages64.html: 438 samples\n",
      "messages65.html: 10 samples\n",
      "messages65.html: 10 samples\n",
      "messages66.html: 6 samples\n",
      "messages66.html: 6 samples\n",
      "messages67.html: 455 samples\n",
      "messages67.html: 455 samples\n",
      "messages68.html: 472 samples\n",
      "messages68.html: 472 samples\n",
      "messages69.html: 414 samples\n",
      "messages69.html: 414 samples\n",
      "messages7.html: 603 samples\n",
      "messages7.html: 603 samples\n",
      "messages70.html: 460 samples\n",
      "messages70.html: 460 samples\n",
      "messages71.html: 461 samples\n",
      "messages71.html: 461 samples\n",
      "messages72.html: 8 samples\n",
      "messages72.html: 8 samples\n",
      "messages73.html: 451 samples\n",
      "messages73.html: 451 samples\n",
      "messages74.html: 410 samples\n",
      "messages74.html: 410 samples\n",
      "messages75.html: 10 samples\n",
      "messages75.html: 10 samples\n",
      "messages76.html: 407 samples\n",
      "messages76.html: 407 samples\n",
      "messages77.html: 423 samples\n",
      "messages77.html: 423 samples\n",
      "messages78.html: 528 samples\n",
      "messages78.html: 528 samples\n",
      "messages79.html: 13 samples\n",
      "messages79.html: 13 samples\n",
      "messages8.html: 16 samples\n",
      "messages8.html: 16 samples\n",
      "messages80.html: 425 samples\n",
      "messages80.html: 425 samples\n",
      "messages81.html: 501 samples\n",
      "messages81.html: 501 samples\n",
      "messages82.html: 18 samples\n",
      "messages82.html: 18 samples\n",
      "messages83.html: 11 samples\n",
      "messages83.html: 11 samples\n",
      "messages84.html: 495 samples\n",
      "messages84.html: 495 samples\n",
      "messages85.html: 480 samples\n",
      "messages85.html: 480 samples\n",
      "messages86.html: 523 samples\n",
      "messages86.html: 523 samples\n",
      "messages87.html: 553 samples\n",
      "messages87.html: 553 samples\n",
      "messages88.html: 455 samples\n",
      "messages88.html: 455 samples\n",
      "messages89.html: 7 samples\n",
      "messages89.html: 7 samples\n",
      "messages9.html: 10 samples\n",
      "messages9.html: 10 samples\n",
      "messages90.html: 441 samples\n",
      "messages90.html: 441 samples\n",
      "messages91.html: 14 samples\n",
      "messages91.html: 14 samples\n",
      "messages92.html: 537 samples\n",
      "messages92.html: 537 samples\n",
      "messages93.html: 529 samples\n",
      "messages93.html: 529 samples\n",
      "messages94.html: 10 samples\n",
      "messages94.html: 10 samples\n",
      "messages95.html: 476 samples\n",
      "messages95.html: 476 samples\n",
      "messages96.html: 460 samples\n",
      "messages96.html: 460 samples\n",
      "messages97.html: 550 samples\n",
      "messages97.html: 550 samples\n",
      "messages98.html: 16 samples\n",
      "messages98.html: 16 samples\n",
      "messages99.html: 503 samples\n",
      "Saved 39572 samples -> dataset.jsonl\n",
      "messages99.html: 503 samples\n",
      "Saved 39572 samples -> dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import jsonlines, re, glob\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# -------- تنظیمات --------\n",
    "WINDOW_SIZE = 15\n",
    "ASSISTANT_NAME = \"Omid\"\n",
    "INPUT_HTML = \"messages.html\"\n",
    "OUTPUT_JSONL = \"dataset.jsonl\"\n",
    "LINK_PLACEHOLDER = \"«لینک»\"   # اگر نمی‌خوای لینک‌ها عوض بشن = None\n",
    "# -------------------------\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s: return \"\"\n",
    "    s = re.sub(r\"⟪REPLY_TO.*?⟫\", \"\", s, flags=re.DOTALL)\n",
    "    if LINK_PLACEHOLDER is not None:\n",
    "        s = s.replace(\"[LINK]\", LINK_PLACEHOLDER)\n",
    "        s = re.sub(r\"https?://\\S+\", LINK_PLACEHOLDER, s)\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def parse_html(path: str) -> List[Dict]:\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    messages, last_sender = [], None\n",
    "    for m in soup.find_all(\"div\", class_=\"message\"):\n",
    "        if \"service\" in m.get(\"class\", []): \n",
    "            continue\n",
    "        body = m.find(\"div\", class_=\"body\")\n",
    "        if not body: \n",
    "            continue\n",
    "\n",
    "        mid_raw = m.get(\"id\", \"\")\n",
    "        mid = int(re.sub(r\"\\D\", \"\", mid_raw)) if mid_raw else None\n",
    "\n",
    "        r = body.find(\"div\", class_=\"reply_to\")\n",
    "        reply_to = None\n",
    "        if r and r.find(\"a\") and r.find(\"a\").get(\"href\"):\n",
    "            href = r.find(\"a\").get(\"href\") or \"\"\n",
    "            ref = re.sub(r\"\\D\", \"\", href)\n",
    "            reply_to = int(ref) if ref else None\n",
    "\n",
    "        name_tag = body.find(\"div\", class_=\"from_name\")\n",
    "        if name_tag: \n",
    "            last_sender = name_tag.get_text(strip=True)\n",
    "        sender = last_sender or \"\"\n",
    "\n",
    "        text_tag = body.find(\"div\", class_=\"text\")\n",
    "        if not text_tag: \n",
    "            continue\n",
    "        content = clean_text(text_tag.get_text(\"\\n\", strip=True))\n",
    "        if not content: \n",
    "            continue\n",
    "\n",
    "        role = \"assistant\" if sender == ASSISTANT_NAME else \"user\"\n",
    "        messages.append({\"id\": mid, \"role\": role, \"sender\": sender, \"content\": content, \"reply_to\": reply_to})\n",
    "    return messages\n",
    "\n",
    "def to_simple(m: Dict) -> Dict:\n",
    "    return {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
    "\n",
    "def merge_same_role(seq: List[Dict]) -> List[Dict]:\n",
    "    out = []\n",
    "    for m in seq:\n",
    "        if not out or out[-1][\"role\"] != m[\"role\"]:\n",
    "            out.append({\"role\": m[\"role\"], \"content\": m[\"content\"]})\n",
    "        else:\n",
    "            out[-1][\"content\"] += \"\\n\" + m[\"content\"]\n",
    "    return out\n",
    "\n",
    "def enforce_user_first_and_alternate(seq: List[Dict]) -> Optional[List[Dict]]:\n",
    "    if not seq: \n",
    "        return None\n",
    "    # نباید با assistant شروع شود و هیچ پیام ساختگی هم اضافه نمی‌کنیم\n",
    "    if seq[0][\"role\"] != \"user\": \n",
    "        return None\n",
    "    seq = merge_same_role(seq)\n",
    "    # اگر با user تمام شد، آن نمونه را کنار بگذاریم (بدون پاسخ)\n",
    "    if seq[-1][\"role\"] != \"assistant\":\n",
    "        return None\n",
    "    # یکی‌درمیان بودن نقش‌ها\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i][\"role\"] == seq[i-1][\"role\"]:\n",
    "            return None\n",
    "    # محتوای خالی حذف\n",
    "    seq = [m for m in seq if m[\"content\"].strip()]\n",
    "    return seq if len(seq) >= 2 else None\n",
    "\n",
    "def get_content(message):\n",
    "    l = \"\"\n",
    "    for i in message:\n",
    "        if i[\"sender\"] != ASSISTANT_NAME:\n",
    "            l += (str(\"دوستم:\" + i[\"content\"]) + \"\\n\")\n",
    "        else:\n",
    "            l += (str(\"من:\" + i[\"content\"]) + \"\\n\")\n",
    "    return l[:-1]\n",
    "\n",
    "\n",
    "def build_dataset(messages: List[Dict], window_size: int = WINDOW_SIZE) -> List[Dict]:\n",
    "    out = []\n",
    "    #print(messages)\n",
    "    for idx, msg in enumerate(messages):\n",
    "        if msg[\"role\"] != \"assistant\":\n",
    "            continue\n",
    "\n",
    "        \n",
    "        out.append({\"history\":get_content(messages[max(0, idx - window_size):idx]), \"response\": msg[\"content\"]})\n",
    "        if idx==20:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "# اجرا برای تمام فایل‌های HTML در این پوشه\n",
    "html_files = sorted(glob.glob(\"*.html\"))\n",
    "\n",
    "total = 0\n",
    "with jsonlines.open(OUTPUT_JSONL, \"w\") as w:\n",
    "    for fp in html_files:\n",
    "        msgs = parse_html(fp)\n",
    "        dataset = build_dataset(msgs, WINDOW_SIZE)\n",
    "        for d in dataset:\n",
    "            w.write(d)\n",
    "        print(f\"{fp}: {len(dataset)} samples\")\n",
    "        total += len(dataset)\n",
    "\n",
    "print(f\"Saved {total} samples -> {OUTPUT_JSONL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc1b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (4.56.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (3.6.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (1.10.1)\n",
      "Requirement already satisfied: peft in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (0.17.1)\n",
      "Requirement already satisfied: trl in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torch in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2025.8.29)\n",
      "Requirement already satisfied: requests in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: psutil in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wandb in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (0.21.3)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (4.25.8)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from wandb) (2.35.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\victor\\.conda\\envs\\finetuining\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victor\\.conda\\envs\\finetuining\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Victor\\AppData\\Roaming\\Python\\Python311\\site-packages\\triton\\windows_utils.py:441: UserWarning: Failed to find CUDA.\n",
      "  warnings.warn(\"Failed to find CUDA.\")\n",
      "W0831 02:01:41.433000 25248 torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Running on CPU - fine-tuning will be slower\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for standard fine-tuning\n",
    "%pip install transformers datasets accelerate peft trl torch\n",
    "%pip install wandb\n",
    "\n",
    "# Modules for fine-tuning\n",
    "import torch # Import PyTorch\n",
    "from transformers import (\n",
    "\tAutoModelForCausalLM, \n",
    "\tAutoTokenizer, \n",
    "\tTrainingArguments,\n",
    "\tTrainer,\n",
    "\tDataCollatorForLanguageModeling\n",
    ")\n",
    "from trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "# Hugging Face modules\n",
    "from huggingface_hub import login # Lets you login to API\n",
    "from datasets import load_dataset # Lets you load fine-tuning datasets\n",
    "# Import weights and biases\n",
    "import wandb\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "\tprint(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "\tprint(\"Running on CPU - fine-tuning will be slower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0c8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
